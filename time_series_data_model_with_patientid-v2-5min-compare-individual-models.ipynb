{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/data2/yinterian/multi-task-romain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5min'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap = \"5min\"\n",
    "gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data_train_{gap}.pickle\".format(gap=gap)\n",
    "with open(PATH/filename, 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data_valid_{gap}.pickle\".format(gap=gap)\n",
    "with open(PATH/filename, 'rb') as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59742, 14), (7086, 14))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_list = np.sort(np.unique(train.subject_id.values))\n",
    "id2index = {v: k+1 for k,v in enumerate(subject_id_list)}\n",
    "num_subjects = len(subject_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2295"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_series(train):\n",
    "    ss = np.concatenate(train.series.values)\n",
    "    ss = ss.reshape(-1,5)\n",
    "    return ss.mean(axis=0), ss.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_static(train):\n",
    "    res = {}\n",
    "    for name in [\"age\", \"sapsii\", \"sofa\"]:\n",
    "        values = train[name].values\n",
    "        res[name] = (values.mean(), values.std())\n",
    "    res[\"series\"] = get_mean_std_series(train)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': (64, 15.073998327645949),\n",
       " 'sapsii': (33, 14.215114554630107),\n",
       " 'sofa': (4, 3.7687923741651197),\n",
       " 'series': (array([ 83.25271123,  93.7286662 , 120.81020051,  58.76277023,\n",
       "          78.52866913]),\n",
       "  array([16.10279665, 17.32261077, 21.2893833 , 12.28384779, 14.32805636]))}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict = get_mean_std_static(train)\n",
    "norm_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTask(Dataset):\n",
    "    def __init__(self, df, norm_dict, id2index, k=20, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: dataframe with data\n",
    "            norm_dict: mean and std of all variables to normalize\n",
    "            \n",
    "        \"\"\"\n",
    "        self.norm_dict = norm_dict\n",
    "        self.df = df\n",
    "        self.names = [\"age\", \"sapsii\", \"sofa\"] ## needs normalization\n",
    "        self.names_binary = [\"gender\", \"amine\", \"sedation\", \"ventilation\"]\n",
    "        self.id2index = id2index\n",
    "        self.train = train\n",
    "        self.df_sample = self.pick_a_sample(k)\n",
    "            \n",
    "    def pick_a_sample(self, k=20):\n",
    "        \"\"\" Picks sample with the same number of observations per patient\"\"\"\n",
    "        if not self.train: # fix seed for validation and test\n",
    "            np.random.seed(3)\n",
    "        sample = self.df.groupby(\"subject_id\", group_keys=False).apply(lambda x: x.sample(min(len(x), k)))\n",
    "        sample = sample.copy()\n",
    "        if self.train:\n",
    "            self.subject_index = [self.id2index[subject_id] for subject_id in sample.subject_id.values]\n",
    "            self.random = np.random.choice(2, sample.shape[0], p=[0.1, 0.9])\n",
    "            self.subject_index = self.subject_index*self.random\n",
    "        return sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df_sample.iloc[index,:]\n",
    "        x_series = (row.series - self.norm_dict[\"series\"][0])/self.norm_dict[\"series\"][1]\n",
    "        x_cont = [(row[name]-self.norm_dict[name][0])/self.norm_dict[name][1] for name in self.names]\n",
    "        x_binary = [row[name] for name in self.names_binary]\n",
    "        subject_index = 0\n",
    "        if self.train:\n",
    "            subject_index = self.subject_index[index]\n",
    "        x_cat = np.array([row[\"care_unit\"], subject_index])\n",
    "        x_cont = np.array(x_cont + x_binary)\n",
    "        return x_series, x_cont, x_cat, row[\"prediction_mean_HR\"], row[\"prediction_mean_MAP\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df_sample.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MultiTask(train, norm_dict, id2index)\n",
    "valid_ds = MultiTask(valid, norm_dict, id2index, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl, which_y=\"y1\"):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    y_hat = []\n",
    "    ys = []\n",
    "    for x_series, x_cont, x_cat, y1, y2 in valid_dl:\n",
    "        batch = y1.shape[0]\n",
    "        x_series = x_series.float().cuda()\n",
    "        x_cont = x_cont.float().cuda()\n",
    "        x_cat = x_cat.long().cuda()\n",
    "        y1 = y1.float().cuda()\n",
    "        y2 = y2.float().cuda()\n",
    "        out = model(x_series, x_cont, x_cat)\n",
    "        if which_y==\"y1\":\n",
    "            mse_loss = F.mse_loss(out, y1.unsqueeze(-1))\n",
    "            ys.append(y1.view(-1).cpu().numpy())\n",
    "        else:\n",
    "            mse_loss = F.mse_loss(out, y2.unsqueeze(-1))\n",
    "            ys.append(y2.view(-1).cpu().numpy())\n",
    "        sum_loss += batch*(mse_loss.item())\n",
    "        total += batch\n",
    "        y_hat.append(out.view(-1).detach().cpu().numpy())\n",
    "    \n",
    "    y_hat = np.concatenate(y_hat)\n",
    "    ys = np.concatenate(ys)\n",
    "    r2 = metrics.r2_score(ys, y_hat)\n",
    "    \n",
    "    return sum_loss/total, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, train_ds, optimizer, lr=1e-3, epochs = 30, which_y=\"y1\"):\n",
    "    prev_val_r2 = 0\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0\n",
    "        total = 0\n",
    "        train_ds.pick_a_sample()\n",
    "        train_dl = DataLoader(train_ds, batch_size=5000, shuffle=True)\n",
    "        for x_series, x_cont, x_cat, y1, y2 in train_dl:\n",
    "            model.train()\n",
    "            x_series = x_series.float().cuda()\n",
    "            x_cont = x_cont.float().cuda()\n",
    "            x_cat = x_cat.long().cuda()\n",
    "            y1 = y1.float().cuda()\n",
    "            y2 = y2.float().cuda()\n",
    "            out = model(x_series, x_cont, x_cat)\n",
    "            if which_y==\"y1\":\n",
    "                loss = F.mse_loss(out, y1.unsqueeze(-1))\n",
    "            else:\n",
    "                loss = F.mse_loss(out, y2.unsqueeze(-1))\n",
    "            sum_loss += len(y1) * loss.item()\n",
    "            \n",
    "            total += len(y1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if i % 1 == 0:\n",
    "            val_loss, val_r2= val_metrics(model, valid_dl, which_y=which_y)\n",
    "            print(\"\\tTrain loss: {:.3f} valid loss: {:.3f} valid r2 {:.3f}\".format(\n",
    "                sum_loss/total, val_loss, val_r2))\n",
    "        if val_r2 > prev_val_r2:\n",
    "            prev_val_r2 = val_r2\n",
    "            if val_r2 > 0.7:\n",
    "                filename = \"single_model_\" + which_y\n",
    "                path = \"{0}/models/{1}_r2_{2:.0f}.pth\".format(PATH, filename, 100*val_r2) \n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel3(nn.Module):\n",
    "    def __init__(self, hidden_size=100, num2=50):\n",
    "        super(EventModel3, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(5, 1)\n",
    "        self.embedding2 = nn.Embedding(num_subjects+1, 5)\n",
    "        self.gru = nn.GRU(5, hidden_size, batch_first=True)\n",
    "        self.num1 = hidden_size + 1 + 5 + 7\n",
    "        self.num2 = num2\n",
    "        self.linear1 = nn.Linear(self.num1, self.num2)\n",
    "        self.linear2 = nn.Linear(self.num2, self.num2)\n",
    "        self.out = nn.Linear(self.num2, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.num2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.num2)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat_1 = self.embedding1(x_cat[:,0])\n",
    "        x_cat_2 = self.embedding2(x_cat[:,1])\n",
    "        x = torch.cat((ht[-1], x_cat_1, x_cat_2, x_cont), 1)\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 7027.162 valid loss: 6767.887 valid r2 -26.826\n",
      "\tTrain loss: 6410.198 valid loss: 5251.317 valid r2 -20.591\n",
      "\tTrain loss: 5351.167 valid loss: 4357.603 valid r2 -16.916\n",
      "\tTrain loss: 3934.455 valid loss: 2791.278 valid r2 -10.476\n",
      "\tTrain loss: 2273.082 valid loss: 1171.302 valid r2 -3.816\n",
      "\tTrain loss: 797.363 valid loss: 131.669 valid r2 0.459\n",
      "\tTrain loss: 81.363 valid loss: 174.506 valid r2 0.283\n",
      "\tTrain loss: 118.801 valid loss: 606.704 valid r2 -1.494\n",
      "\tTrain loss: 188.583 valid loss: 292.491 valid r2 -0.203\n",
      "\tTrain loss: 69.507 valid loss: 29.622 valid r2 0.878\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_88.pth\n",
      "\tTrain loss: 11.799 valid loss: 13.491 valid r2 0.945\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_94.pth\n",
      "\tTrain loss: 24.767 valid loss: 17.606 valid r2 0.928\n",
      "\tTrain loss: 23.798 valid loss: 11.641 valid r2 0.952\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_95.pth\n",
      "\tTrain loss: 11.071 valid loss: 6.012 valid r2 0.975\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_98.pth\n",
      "\tTrain loss: 8.400 valid loss: 8.735 valid r2 0.964\n"
     ]
    }
   ],
   "source": [
    "# model for mean_HR\n",
    "model = EventModel3().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-5)\n",
    "train_epochs(model, train_ds, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 15.010 valid loss: 38.459 valid r2 0.842\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_84.pth\n",
      "\tTrain loss: 9.652 valid loss: 28.744 valid r2 0.882\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_88.pth\n",
      "\tTrain loss: 8.770 valid loss: 8.099 valid r2 0.967\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_97.pth\n",
      "\tTrain loss: 8.543 valid loss: 9.486 valid r2 0.961\n",
      "\tTrain loss: 8.205 valid loss: 7.106 valid r2 0.971\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_97.pth\n",
      "\tTrain loss: 7.869 valid loss: 6.949 valid r2 0.971\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_97.pth\n",
      "\tTrain loss: 7.743 valid loss: 6.283 valid r2 0.974\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_97.pth\n",
      "\tTrain loss: 7.480 valid loss: 6.008 valid r2 0.975\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_98.pth\n",
      "\tTrain loss: 7.521 valid loss: 6.173 valid r2 0.975\n",
      "\tTrain loss: 7.519 valid loss: 6.513 valid r2 0.973\n",
      "\tTrain loss: 7.224 valid loss: 6.029 valid r2 0.975\n",
      "\tTrain loss: 7.222 valid loss: 6.346 valid r2 0.974\n",
      "\tTrain loss: 7.061 valid loss: 6.416 valid r2 0.974\n",
      "\tTrain loss: 7.068 valid loss: 5.788 valid r2 0.976\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y1_r2_98.pth\n",
      "\tTrain loss: 6.908 valid loss: 5.962 valid r2 0.975\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02, weight_decay=1e-5)\n",
    "train_epochs(model, train_ds, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 6136.813 valid loss: 6055.551 valid r2 -33.875\n",
      "\tTrain loss: 5578.118 valid loss: 4739.408 valid r2 -26.295\n",
      "\tTrain loss: 4633.098 valid loss: 3592.138 valid r2 -19.688\n",
      "\tTrain loss: 3333.216 valid loss: 2427.078 valid r2 -12.978\n",
      "\tTrain loss: 1821.558 valid loss: 1263.982 valid r2 -6.279\n",
      "\tTrain loss: 544.337 valid loss: 119.247 valid r2 0.313\n",
      "\tTrain loss: 50.737 valid loss: 54.172 valid r2 0.688\n",
      "\tTrain loss: 149.538 valid loss: 89.306 valid r2 0.486\n",
      "\tTrain loss: 161.458 valid loss: 39.973 valid r2 0.770\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_77.pth\n",
      "\tTrain loss: 43.642 valid loss: 10.027 valid r2 0.942\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_94.pth\n",
      "\tTrain loss: 17.790 valid loss: 39.479 valid r2 0.773\n",
      "\tTrain loss: 31.561 valid loss: 37.628 valid r2 0.783\n",
      "\tTrain loss: 23.532 valid loss: 14.506 valid r2 0.916\n",
      "\tTrain loss: 13.011 valid loss: 11.678 valid r2 0.933\n",
      "\tTrain loss: 13.557 valid loss: 13.187 valid r2 0.924\n"
     ]
    }
   ],
   "source": [
    "# mean_MAP\n",
    "model = EventModel3().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-5)\n",
    "train_epochs(model, train_ds, optimizer, epochs=15, which_y=\"y2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 15.322 valid loss: 34.684 valid r2 0.800\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_80.pth\n",
      "\tTrain loss: 13.476 valid loss: 11.070 valid r2 0.936\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_94.pth\n",
      "\tTrain loss: 12.788 valid loss: 10.266 valid r2 0.941\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_94.pth\n",
      "\tTrain loss: 12.102 valid loss: 9.983 valid r2 0.943\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_94.pth\n",
      "\tTrain loss: 11.832 valid loss: 9.566 valid r2 0.945\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_94.pth\n",
      "\tTrain loss: 11.402 valid loss: 9.254 valid r2 0.947\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_95.pth\n",
      "\tTrain loss: 11.088 valid loss: 9.242 valid r2 0.947\n",
      "/data2/yinterian/multi-task-romain/models/single_model_y2_r2_95.pth\n",
      "\tTrain loss: 11.048 valid loss: 9.779 valid r2 0.944\n",
      "\tTrain loss: 10.700 valid loss: 9.541 valid r2 0.945\n",
      "\tTrain loss: 10.631 valid loss: 9.818 valid r2 0.943\n",
      "\tTrain loss: 10.793 valid loss: 9.752 valid r2 0.944\n",
      "\tTrain loss: 10.344 valid loss: 9.513 valid r2 0.945\n",
      "\tTrain loss: 10.114 valid loss: 10.272 valid r2 0.941\n",
      "\tTrain loss: 10.028 valid loss: 9.692 valid r2 0.944\n",
      "\tTrain loss: 9.848 valid loss: 9.754 valid r2 0.944\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02, weight_decay=1e-5)\n",
    "train_epochs(model, train_ds, optimizer, epochs=15, which_y=\"y2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"models/single_model_y1_r2_98.pth\"\n",
    "model = EventModel3().cuda()\n",
    "load_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_test_5min.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = \"data_test_{gap}.pickle\".format(gap=gap)\n",
    "with open(PATH/filename, 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8233, 14), 4561)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = MultiTask(test, norm_dict, id2index, k=25, train=False)\n",
    "test.shape, len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size=4561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.7878594398498535, 0.9762034642736148)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl, which_y=\"y1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"models/single_model_y2_r2_95.pth\"\n",
    "load_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.241517066955566, 0.9467764570505772)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl, which_y=\"y2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data_train_{gap}.pickle\".format(gap=\"5min\")\n",
    "with open(PATH/filename, 'rb') as f:\n",
    "    train5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data_train_{gap}.pickle\".format(gap=\"10min\")\n",
    "with open(PATH/filename, 'rb') as f:\n",
    "    train10 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"subject_id\", \"key\", \"prediction_mean_HR\", \"prediction_mean_MAP\"]\n",
    "train5_s = train5.loc[:, cols]\n",
    "train10_s = train10.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>key</th>\n",
       "      <th>prediction_mean_HR</th>\n",
       "      <th>prediction_mean_MAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_18</td>\n",
       "      <td>95.44</td>\n",
       "      <td>55.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_19</td>\n",
       "      <td>107.4</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_20</td>\n",
       "      <td>102.08</td>\n",
       "      <td>68.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_23</td>\n",
       "      <td>99.14</td>\n",
       "      <td>86.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_24</td>\n",
       "      <td>108.1</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_25</td>\n",
       "      <td>106.44</td>\n",
       "      <td>57.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_27</td>\n",
       "      <td>95.24</td>\n",
       "      <td>58.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_28</td>\n",
       "      <td>91.94</td>\n",
       "      <td>60.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_29</td>\n",
       "      <td>88.9</td>\n",
       "      <td>55.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_30</td>\n",
       "      <td>89.8</td>\n",
       "      <td>59.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_31</td>\n",
       "      <td>85.76</td>\n",
       "      <td>55.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_32</td>\n",
       "      <td>86.28</td>\n",
       "      <td>57.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_33</td>\n",
       "      <td>82.92</td>\n",
       "      <td>48.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_34</td>\n",
       "      <td>85.24</td>\n",
       "      <td>49.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_36</td>\n",
       "      <td>86.2</td>\n",
       "      <td>57.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_37</td>\n",
       "      <td>83.74</td>\n",
       "      <td>54.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_38</td>\n",
       "      <td>83.92</td>\n",
       "      <td>59.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_39</td>\n",
       "      <td>85.78</td>\n",
       "      <td>62.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_40</td>\n",
       "      <td>85.72</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_41</td>\n",
       "      <td>85.5</td>\n",
       "      <td>55.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_42</td>\n",
       "      <td>92.06</td>\n",
       "      <td>61.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_43</td>\n",
       "      <td>90.92</td>\n",
       "      <td>56.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_44</td>\n",
       "      <td>91.2</td>\n",
       "      <td>52.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_45</td>\n",
       "      <td>87.32</td>\n",
       "      <td>45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_46</td>\n",
       "      <td>86.74</td>\n",
       "      <td>45.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_47</td>\n",
       "      <td>86.4</td>\n",
       "      <td>48.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_48</td>\n",
       "      <td>86.94</td>\n",
       "      <td>48.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_50</td>\n",
       "      <td>87.36</td>\n",
       "      <td>55.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_51</td>\n",
       "      <td>88.36</td>\n",
       "      <td>60.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_52</td>\n",
       "      <td>88.86</td>\n",
       "      <td>60.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id       key prediction_mean_HR prediction_mean_MAP\n",
       "0       10013  10013_18              95.44               55.88\n",
       "1       10013  10013_19              107.4                68.4\n",
       "2       10013  10013_20             102.08               68.28\n",
       "3       10013  10013_23              99.14               86.14\n",
       "4       10013  10013_24              108.1               69.96\n",
       "5       10013  10013_25             106.44               57.74\n",
       "6       10013  10013_27              95.24               58.78\n",
       "7       10013  10013_28              91.94               60.92\n",
       "8       10013  10013_29               88.9               55.74\n",
       "9       10013  10013_30               89.8               59.42\n",
       "10      10013  10013_31              85.76               55.78\n",
       "11      10013  10013_32              86.28               57.12\n",
       "12      10013  10013_33              82.92               48.96\n",
       "13      10013  10013_34              85.24               49.46\n",
       "14      10013  10013_36               86.2               57.06\n",
       "15      10013  10013_37              83.74               54.76\n",
       "16      10013  10013_38              83.92               59.58\n",
       "17      10013  10013_39              85.78               62.02\n",
       "18      10013  10013_40              85.72               56.58\n",
       "19      10013  10013_41               85.5               55.84\n",
       "20      10013  10013_42              92.06                61.9\n",
       "21      10013  10013_43              90.92               56.16\n",
       "22      10013  10013_44               91.2               52.08\n",
       "23      10013  10013_45              87.32                45.2\n",
       "24      10013  10013_46              86.74               45.12\n",
       "25      10013  10013_47               86.4               48.04\n",
       "26      10013  10013_48              86.94               48.06\n",
       "27      10013  10013_50              87.36               55.74\n",
       "28      10013  10013_51              88.36               60.38\n",
       "29      10013  10013_52              88.86               60.12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train5_s.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>key</th>\n",
       "      <th>prediction_mean_HR</th>\n",
       "      <th>prediction_mean_MAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_16</td>\n",
       "      <td>95.44</td>\n",
       "      <td>55.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_17</td>\n",
       "      <td>83.92</td>\n",
       "      <td>70.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_18</td>\n",
       "      <td>100.14</td>\n",
       "      <td>65.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_21</td>\n",
       "      <td>102.86</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_22</td>\n",
       "      <td>109.3</td>\n",
       "      <td>61.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_25</td>\n",
       "      <td>91.32</td>\n",
       "      <td>60.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_26</td>\n",
       "      <td>91.34</td>\n",
       "      <td>56.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_27</td>\n",
       "      <td>89.42</td>\n",
       "      <td>57.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_28</td>\n",
       "      <td>85.9</td>\n",
       "      <td>59.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_29</td>\n",
       "      <td>83</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_30</td>\n",
       "      <td>83.98</td>\n",
       "      <td>48.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_32</td>\n",
       "      <td>86.2</td>\n",
       "      <td>57.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_33</td>\n",
       "      <td>83.4</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_34</td>\n",
       "      <td>86.66</td>\n",
       "      <td>64.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_35</td>\n",
       "      <td>85.16</td>\n",
       "      <td>58.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_36</td>\n",
       "      <td>85.76</td>\n",
       "      <td>56.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_37</td>\n",
       "      <td>88.6</td>\n",
       "      <td>59.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_38</td>\n",
       "      <td>90.58</td>\n",
       "      <td>59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_39</td>\n",
       "      <td>92.78</td>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_40</td>\n",
       "      <td>87.32</td>\n",
       "      <td>45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_41</td>\n",
       "      <td>86.92</td>\n",
       "      <td>46.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_42</td>\n",
       "      <td>87.06</td>\n",
       "      <td>48.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_45</td>\n",
       "      <td>88.06</td>\n",
       "      <td>58.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_46</td>\n",
       "      <td>88.94</td>\n",
       "      <td>58.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_47</td>\n",
       "      <td>88.38</td>\n",
       "      <td>56.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_48</td>\n",
       "      <td>87.74</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_49</td>\n",
       "      <td>85.84</td>\n",
       "      <td>47.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_50</td>\n",
       "      <td>83.62</td>\n",
       "      <td>44.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_51</td>\n",
       "      <td>84.16</td>\n",
       "      <td>37.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013_52</td>\n",
       "      <td>85.3</td>\n",
       "      <td>43.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id       key prediction_mean_HR prediction_mean_MAP\n",
       "0       10013  10013_16              95.44               55.88\n",
       "1       10013  10013_17              83.92               70.28\n",
       "2       10013  10013_18             100.14               65.08\n",
       "3       10013  10013_21             102.86                70.6\n",
       "4       10013  10013_22              109.3               61.86\n",
       "5       10013  10013_25              91.32               60.22\n",
       "6       10013  10013_26              91.34               56.04\n",
       "7       10013  10013_27              89.42               57.34\n",
       "8       10013  10013_28               85.9               59.22\n",
       "9       10013  10013_29                 83                  52\n",
       "10      10013  10013_30              83.98               48.78\n",
       "11      10013  10013_32               86.2               57.06\n",
       "12      10013  10013_33               83.4               55.56\n",
       "13      10013  10013_34              86.66               64.56\n",
       "14      10013  10013_35              85.16               58.88\n",
       "15      10013  10013_36              85.76               56.68\n",
       "16      10013  10013_37               88.6               59.76\n",
       "17      10013  10013_38              90.58               59.84\n",
       "18      10013  10013_39              92.78                55.2\n",
       "19      10013  10013_40              87.32                45.2\n",
       "20      10013  10013_41              86.92               46.14\n",
       "21      10013  10013_42              87.06               48.56\n",
       "22      10013  10013_45              88.06               58.72\n",
       "23      10013  10013_46              88.94               58.08\n",
       "24      10013  10013_47              88.38                56.6\n",
       "25      10013  10013_48              87.74                55.8\n",
       "26      10013  10013_49              85.84               47.82\n",
       "27      10013  10013_50              83.62               44.94\n",
       "28      10013  10013_51              84.16               37.76\n",
       "29      10013  10013_52               85.3               43.82"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train10_s.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
