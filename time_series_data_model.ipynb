{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/data2/yinterian/multi-task-romain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/\"obs_df_train.pickle\", 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/\"obs_df_valid.pickle\", 'rb') as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sapsi_first</th>\n",
       "      <th>sofa_first</th>\n",
       "      <th>care_unit</th>\n",
       "      <th>amine</th>\n",
       "      <th>sedation</th>\n",
       "      <th>ventilation</th>\n",
       "      <th>period</th>\n",
       "      <th>series</th>\n",
       "      <th>y_event</th>\n",
       "      <th>y_mean_abpm</th>\n",
       "      <th>is_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[[85.0, 89.1, 106.8, 31.5, 52.2], [84.9, 88.2,...</td>\n",
       "      <td>1</td>\n",
       "      <td>62.465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[[85.9, 88.3, 123.2, 38.6, 63.2], [85.5, 91.7,...</td>\n",
       "      <td>1</td>\n",
       "      <td>56.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[[85.6, 93.6, 108.4, 34.7, 55.9], [86.0, 93.9,...</td>\n",
       "      <td>1</td>\n",
       "      <td>60.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[[86.9, 0.0, 95.3, 30.0, 48.5], [87.4, 0.0, 94...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[[87.3, 90.6, 105.9, 36.1, 55.9], [86.8, 91.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>57.965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  gender age sapsi_first sofa_first  care_unit amine sedation  \\\n",
       "0      10013       1  87          15          8          0     1        0   \n",
       "1      10013       1  87          15          8          0     1        0   \n",
       "2      10013       1  87          15          8          0     1        0   \n",
       "3      10013       1  87          15          8          0     1        0   \n",
       "4      10013       1  87          15          8          0     1        0   \n",
       "\n",
       "  ventilation period                                             series  \\\n",
       "0           0     10  [[85.0, 89.1, 106.8, 31.5, 52.2], [84.9, 88.2,...   \n",
       "1           0     11  [[85.9, 88.3, 123.2, 38.6, 63.2], [85.5, 91.7,...   \n",
       "2           0     12  [[85.6, 93.6, 108.4, 34.7, 55.9], [86.0, 93.9,...   \n",
       "3           0     15  [[86.9, 0.0, 95.3, 30.0, 48.5], [87.4, 0.0, 94...   \n",
       "4           0     16  [[87.3, 90.6, 105.9, 36.1, 55.9], [86.8, 91.0,...   \n",
       "\n",
       "  y_event y_mean_abpm  is_val  \n",
       "0       1      62.465       0  \n",
       "1       1      56.505       0  \n",
       "2       1       60.52       0  \n",
       "3       1       55.23       0  \n",
       "4       1      57.965       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sapsi_first</th>\n",
       "      <th>sofa_first</th>\n",
       "      <th>care_unit</th>\n",
       "      <th>amine</th>\n",
       "      <th>sedation</th>\n",
       "      <th>ventilation</th>\n",
       "      <th>period</th>\n",
       "      <th>series</th>\n",
       "      <th>y_event</th>\n",
       "      <th>y_mean_abpm</th>\n",
       "      <th>is_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[101.1, 100.0, 149.3, 94.5, 115.7], [101.3, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>107.575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>[[89.0, 100.0, 133.6, 69.2, 88.2], [89.1, 100....</td>\n",
       "      <td>0</td>\n",
       "      <td>90.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>[[89.8, 97.9, 141.9, 71.2, 89.9], [89.8, 97.5,...</td>\n",
       "      <td>0</td>\n",
       "      <td>96.515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>[[89.4, 99.0, 159.3, 77.4, 98.1], [89.1, 99.3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>97.355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>[[87.0, 99.0, 166.9, 78.4, 101.6], [90.6, 99.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>102.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  gender age sapsi_first sofa_first  care_unit amine sedation  \\\n",
       "221      10209       0  35          16          7          1     1        1   \n",
       "222      10209       0  35          16          7          1     1        1   \n",
       "223      10209       0  35          16          7          1     1        1   \n",
       "224      10209       0  35          16          7          1     1        1   \n",
       "225      10209       0  35          16          7          1     1        1   \n",
       "\n",
       "    ventilation period                                             series  \\\n",
       "221           1     10  [[101.1, 100.0, 149.3, 94.5, 115.7], [101.3, 1...   \n",
       "222           1    102  [[89.0, 100.0, 133.6, 69.2, 88.2], [89.1, 100....   \n",
       "223           1    103  [[89.8, 97.9, 141.9, 71.2, 89.9], [89.8, 97.5,...   \n",
       "224           1    104  [[89.4, 99.0, 159.3, 77.4, 98.1], [89.1, 99.3,...   \n",
       "225           1    106  [[87.0, 99.0, 166.9, 78.4, 101.6], [90.6, 99.0...   \n",
       "\n",
       "    y_event y_mean_abpm  is_val  \n",
       "221       0     107.575       1  \n",
       "222       0       90.04       1  \n",
       "223       0      96.515       1  \n",
       "224       0      97.355       1  \n",
       "225       0      102.24       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32256, 14), (7332, 14))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_series(train):\n",
    "    ss = np.concatenate(train.series.values)\n",
    "    ss = ss.reshape(-1,5)\n",
    "    return ss.mean(axis=0), ss.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_static(train):\n",
    "    res = {}\n",
    "    for name in [\"age\", \"sapsi_first\", \"sofa_first\"]:\n",
    "        values = train[name].values\n",
    "        res[name] = (values.mean(), values.std())\n",
    "    res[\"series\"] = get_mean_std_series(train)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': (67, 16.152217089222916),\n",
       " 'sapsi_first': (16, 4.968204119744002),\n",
       " 'sofa_first': (8, 4.153183597602336),\n",
       " 'series': (array([ 85.78689748,  90.61373362, 118.25838821,  57.44024058,\n",
       "          81.28476211]),\n",
       "  array([16.91317423, 24.11194065, 31.60648773, 17.01183444, 20.30982141]))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict = get_mean_std_static(train)\n",
    "norm_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTask(Dataset):\n",
    "    def __init__(self, df, norm_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: dataframe with data\n",
    "            norm_dict: mean and std of all variables to normalize\n",
    "            \n",
    "        \"\"\"\n",
    "        self.norm_dict = norm_dict\n",
    "        self.df = df\n",
    "        self.names = [\"age\", \"sapsi_first\", \"sofa_first\"] ## needs normalization\n",
    "        self.names_binary = [\"gender\", \"amine\", \"sedation\", \"ventilation\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index,:]\n",
    "        x_series = (row.series - self.norm_dict[\"series\"][0])/self.norm_dict[\"series\"][1]\n",
    "        x_cont = [(row[name]-self.norm_dict[name][0])/self.norm_dict[name][1] for name in self.names]\n",
    "        x_binary = [row[name] for name in self.names_binary]\n",
    "        x_cat = row[\"care_unit\"]\n",
    "        x_cont = np.array(x_cont + x_binary)\n",
    "        return x_series, x_cont, x_cat, row[\"y_event\"], row[\"y_mean_abpm\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MultiTask(train, norm_dict)\n",
    "valid_ds = MultiTask(valid, norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3, y1, y2 = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_series, x_cont, x_cat, y1, y2 = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 60, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(5, 11, batch_first=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 11])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts, ht = gru(x_series.float().cuda())\n",
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 11])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 60, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "embedding = nn.Embedding(3, 1).cuda()\n",
    "gru = nn.GRU(5, hidden_size, bidirectional=True, batch_first=True).cuda()\n",
    "num = hidden_size + 10 + 1\n",
    "linear1 = nn.Linear(7, 10).cuda()\n",
    "out1 = nn.Linear(num, 1).cuda()\n",
    "out2 = nn.Linear(num, 1).cuda()\n",
    "bn1 = nn.BatchNorm1d(10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_series, x_cont, x_cat, y1, y2 = next(iter(train_dl))\n",
    "x_series = x_series.float().cuda()\n",
    "x_cont = x_cont.float().cuda()\n",
    "x_cat = x_cat.long().cuda()\n",
    "y1 = y1.float().cuda()\n",
    "y2 = y2.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ht = gru(x_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(EventModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(5, hidden_size, batch_first=True)\n",
    "        self.num = hidden_size + 10 + 1\n",
    "        self.linear1 = nn.Linear(7, 10)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x_cont = self.bn1(F.relu(self.linear1(x_cont))) \n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel2(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(EventModel2, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(5, hidden_size, batch_first=True)\n",
    "        self.num = hidden_size + 7 + 1\n",
    "        self.linear1 = nn.Linear(7, 7)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x_cont = self.bn1(F.relu(self.linear1(x_cont))) + x_cont\n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel3(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(EventModel3, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(5, hidden_size, batch_first=True)\n",
    "        self.num = hidden_size + 7 + 1\n",
    "        self.linear1 = nn.Linear(self.num, self.num)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.num)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    y_hat1 = []\n",
    "    ys1 = []\n",
    "    y_hat2 = []\n",
    "    ys2 = []\n",
    "    for x_series, x_cont, x_cat, y1, y2 in valid_dl:\n",
    "        batch = y1.shape[0]\n",
    "        x_series = x_series.float().cuda()\n",
    "        x_cont = x_cont.float().cuda()\n",
    "        x_cat = x_cat.long().cuda()\n",
    "        y1 = y1.float().cuda()\n",
    "        y2 = y2.float().cuda()\n",
    "        out1, out2 = model(x_series, x_cont, x_cat)\n",
    "        log_loss = F.binary_cross_entropy_with_logits(out1, y1.unsqueeze(-1))\n",
    "        mse_loss = F.mse_loss(out2, y2.unsqueeze(-1))\n",
    "        loss = log_loss + mse_loss\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        y_hat1.append(out1.view(-1).detach().cpu().numpy())\n",
    "        ys1.append(y1.view(-1).cpu().numpy())\n",
    "        y_hat2.append(out2.view(-1).detach().cpu().numpy())\n",
    "        ys2.append(y2.view(-1).cpu().numpy())\n",
    "    \n",
    "    y_hat1 = np.concatenate(y_hat1)\n",
    "    y_hat2 = np.concatenate(y_hat2)\n",
    "    ys1 = np.concatenate(ys1)\n",
    "    ys2 = np.concatenate(ys2)\n",
    "    r2 = metrics.r2_score(ys2, y_hat2)\n",
    "    auc = metrics.roc_auc_score(ys1, y_hat1)\n",
    "    return sum_loss/total, auc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, train_dl, optimizer, filename, lr=1e-3, epochs = 30):\n",
    "    prev_val_r2 = 0\n",
    "    for i in range(epochs):\n",
    "        sum_loss1 = 0\n",
    "        sum_loss2 = 0\n",
    "        total = 0\n",
    "        for x_series, x_cont, x_cat, y1, y2 in train_dl:\n",
    "            model.train()\n",
    "            x_series = x_series.float().cuda()\n",
    "            x_cont = x_cont.float().cuda()\n",
    "            x_cat = x_cat.long().cuda()\n",
    "            y1 = y1.float().cuda()\n",
    "            y2 = y2.float().cuda()\n",
    "            out1, out2 = model(x_series, x_cont, x_cat)\n",
    "            log_loss = F.binary_cross_entropy_with_logits(out1, y1.unsqueeze(-1))\n",
    "            mse_loss = F.mse_loss(out2, y2.unsqueeze(-1))\n",
    "            loss = log_loss + mse_loss\n",
    "            sum_loss1 += len(y1) * log_loss.item()\n",
    "            sum_loss2 += len(y1) * mse_loss.item()\n",
    "            total += len(y1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if i % 1 == 0:\n",
    "            val_loss, val_auc, val_r2 = val_metrics(model, valid_dl)\n",
    "            print(\"\\tTrain loss: {:.3f} {:.3f} valid loss: {:.3f} valid auc {:.3f} valid r2 {:.3f}\".format(\n",
    "                sum_loss1/total, sum_loss2/total, val_loss, val_auc, val_r2))\n",
    "            \n",
    "        if val_r2 > prev_val_r2:\n",
    "            prev_val_r2 = val_r2\n",
    "            if val_r2 > 0.7:\n",
    "                path = \"{0}/models/{1}_r2_{2:.0f}_auc_{3:.0f}.pth\".format(PATH, filename, 100*val_r2, 100*val_auc) \n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EventModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.558 5540.801 valid loss: 3497.681 valid auc 0.892 valid r2 -9.719\n",
      "\tTrain loss: 0.355 2283.166 valid loss: 832.262 valid auc 0.891 valid r2 -1.550\n",
      "\tTrain loss: 0.344 411.508 valid loss: 275.807 valid auc 0.898 valid r2 0.156\n",
      "\tTrain loss: 0.322 309.826 valid loss: 332.436 valid auc 0.887 valid r2 -0.018\n",
      "\tTrain loss: 0.332 256.891 valid loss: 187.423 valid auc 0.875 valid r2 0.427\n",
      "\tTrain loss: 0.340 159.971 valid loss: 176.174 valid auc 0.866 valid r2 0.461\n",
      "\tTrain loss: 0.343 158.754 valid loss: 172.762 valid auc 0.884 valid r2 0.472\n",
      "\tTrain loss: 0.335 145.260 valid loss: 154.841 valid auc 0.880 valid r2 0.526\n",
      "\tTrain loss: 0.333 134.529 valid loss: 149.408 valid auc 0.878 valid r2 0.543\n",
      "\tTrain loss: 0.325 129.455 valid loss: 143.152 valid auc 0.883 valid r2 0.562\n",
      "\tTrain loss: 0.319 124.147 valid loss: 138.674 valid auc 0.888 valid r2 0.576\n",
      "\tTrain loss: 0.317 121.214 valid loss: 134.927 valid auc 0.892 valid r2 0.587\n",
      "\tTrain loss: 0.314 118.616 valid loss: 132.025 valid auc 0.893 valid r2 0.596\n",
      "\tTrain loss: 0.313 116.184 valid loss: 130.007 valid auc 0.899 valid r2 0.602\n",
      "\tTrain loss: 0.309 114.868 valid loss: 130.008 valid auc 0.900 valid r2 0.602\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, train_dl, optimizer, filename=\"model1\", epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.460 126.937 valid loss: 124.748 valid auc 0.902 valid r2 0.619\n",
      "\tTrain loss: 0.354 110.977 valid loss: 123.678 valid auc 0.904 valid r2 0.622\n",
      "\tTrain loss: 0.331 107.793 valid loss: 119.566 valid auc 0.906 valid r2 0.634\n",
      "\tTrain loss: 0.307 105.259 valid loss: 117.457 valid auc 0.906 valid r2 0.641\n",
      "\tTrain loss: 0.298 102.716 valid loss: 114.973 valid auc 0.908 valid r2 0.649\n",
      "\tTrain loss: 0.292 100.406 valid loss: 112.576 valid auc 0.910 valid r2 0.656\n",
      "\tTrain loss: 0.288 97.998 valid loss: 110.091 valid auc 0.911 valid r2 0.663\n",
      "\tTrain loss: 0.290 95.805 valid loss: 109.674 valid auc 0.910 valid r2 0.665\n",
      "\tTrain loss: 0.289 94.075 valid loss: 108.451 valid auc 0.912 valid r2 0.669\n",
      "\tTrain loss: 0.285 92.088 valid loss: 106.796 valid auc 0.917 valid r2 0.674\n",
      "\tTrain loss: 0.278 90.476 valid loss: 105.235 valid auc 0.921 valid r2 0.678\n",
      "\tTrain loss: 0.279 89.003 valid loss: 106.356 valid auc 0.920 valid r2 0.675\n",
      "\tTrain loss: 0.276 88.237 valid loss: 103.477 valid auc 0.920 valid r2 0.684\n",
      "\tTrain loss: 0.274 87.109 valid loss: 103.163 valid auc 0.922 valid r2 0.685\n",
      "\tTrain loss: 0.272 85.658 valid loss: 104.082 valid auc 0.923 valid r2 0.682\n",
      "\tTrain loss: 0.271 84.958 valid loss: 103.103 valid auc 0.923 valid r2 0.685\n",
      "\tTrain loss: 0.274 83.669 valid loss: 102.427 valid auc 0.922 valid r2 0.687\n",
      "\tTrain loss: 0.271 83.035 valid loss: 102.411 valid auc 0.921 valid r2 0.687\n",
      "\tTrain loss: 0.274 82.179 valid loss: 101.256 valid auc 0.920 valid r2 0.691\n",
      "\tTrain loss: 0.275 82.653 valid loss: 100.653 valid auc 0.923 valid r2 0.692\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-5)\n",
    "train_epochs(model, train_dl, optimizer,filename=\"model1\", epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"{0}/models/model0_acc_92_r2_{1:.0f}.pth\".format(PATH, 100*0.69) \n",
    "save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.557 5656.964 valid loss: 3546.525 valid auc 0.840 valid r2 -9.868\n",
      "\tTrain loss: 0.415 2248.717 valid loss: 862.392 valid auc 0.880 valid r2 -1.642\n",
      "\tTrain loss: 0.373 401.649 valid loss: 275.263 valid auc 0.896 valid r2 0.157\n",
      "\tTrain loss: 0.343 374.347 valid loss: 385.253 valid auc 0.892 valid r2 -0.180\n",
      "\tTrain loss: 0.365 315.856 valid loss: 208.421 valid auc 0.870 valid r2 0.362\n",
      "\tTrain loss: 0.356 173.524 valid loss: 193.626 valid auc 0.849 valid r2 0.408\n",
      "\tTrain loss: 0.354 175.444 valid loss: 193.976 valid auc 0.861 valid r2 0.407\n",
      "\tTrain loss: 0.345 164.000 valid loss: 169.304 valid auc 0.877 valid r2 0.482\n",
      "\tTrain loss: 0.333 147.575 valid loss: 159.866 valid auc 0.883 valid r2 0.511\n",
      "\tTrain loss: 0.328 140.912 valid loss: 156.455 valid auc 0.876 valid r2 0.522\n",
      "\tTrain loss: 0.333 143.350 valid loss: 147.939 valid auc 0.873 valid r2 0.548\n",
      "\tTrain loss: 0.329 133.951 valid loss: 148.193 valid auc 0.877 valid r2 0.547\n",
      "\tTrain loss: 0.328 128.605 valid loss: 141.732 valid auc 0.876 valid r2 0.567\n",
      "\tTrain loss: 0.327 123.859 valid loss: 137.898 valid auc 0.879 valid r2 0.578\n",
      "\tTrain loss: 0.323 120.478 valid loss: 133.780 valid auc 0.886 valid r2 0.591\n"
     ]
    }
   ],
   "source": [
    "# new try\n",
    "model = EventModel().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model1\", epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.499 118.792 valid loss: 128.645 valid auc 0.890 valid r2 0.607\n",
      "\tTrain loss: 0.387 111.989 valid loss: 123.553 valid auc 0.893 valid r2 0.622\n",
      "\tTrain loss: 0.337 105.941 valid loss: 116.206 valid auc 0.898 valid r2 0.645\n",
      "\tTrain loss: 0.317 102.208 valid loss: 115.273 valid auc 0.897 valid r2 0.648\n",
      "\tTrain loss: 0.311 98.768 valid loss: 111.532 valid auc 0.904 valid r2 0.659\n",
      "\tTrain loss: 0.302 96.312 valid loss: 108.222 valid auc 0.907 valid r2 0.669\n",
      "\tTrain loss: 0.293 94.110 valid loss: 107.289 valid auc 0.910 valid r2 0.672\n",
      "\tTrain loss: 0.290 92.537 valid loss: 105.342 valid auc 0.912 valid r2 0.678\n",
      "\tTrain loss: 0.285 90.009 valid loss: 104.592 valid auc 0.914 valid r2 0.680\n",
      "\tTrain loss: 0.283 89.789 valid loss: 103.115 valid auc 0.916 valid r2 0.685\n",
      "\tTrain loss: 0.282 87.671 valid loss: 103.057 valid auc 0.920 valid r2 0.685\n",
      "\tTrain loss: 0.281 86.796 valid loss: 102.229 valid auc 0.920 valid r2 0.688\n",
      "\tTrain loss: 0.285 85.696 valid loss: 101.696 valid auc 0.918 valid r2 0.689\n",
      "\tTrain loss: 0.288 85.650 valid loss: 101.313 valid auc 0.916 valid r2 0.690\n",
      "\tTrain loss: 0.283 86.788 valid loss: 101.256 valid auc 0.919 valid r2 0.690\n",
      "\tTrain loss: 0.275 86.444 valid loss: 101.024 valid auc 0.918 valid r2 0.691\n",
      "\tTrain loss: 0.280 84.644 valid loss: 101.720 valid auc 0.920 valid r2 0.689\n",
      "\tTrain loss: 0.276 84.080 valid loss: 102.663 valid auc 0.921 valid r2 0.686\n",
      "\tTrain loss: 0.282 85.403 valid loss: 102.701 valid auc 0.917 valid r2 0.686\n",
      "\tTrain loss: 0.288 83.884 valid loss: 99.669 valid auc 0.920 valid r2 0.695\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model1\", epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.572 5471.378 valid loss: 3427.993 valid auc 0.851 valid r2 -9.505\n",
      "\tTrain loss: 0.410 2313.734 valid loss: 905.162 valid auc 0.882 valid r2 -1.773\n",
      "\tTrain loss: 0.367 462.863 valid loss: 221.941 valid auc 0.892 valid r2 0.321\n",
      "\tTrain loss: 0.336 277.959 valid loss: 380.718 valid auc 0.888 valid r2 -0.166\n",
      "\tTrain loss: 0.343 287.511 valid loss: 213.315 valid auc 0.891 valid r2 0.347\n",
      "\tTrain loss: 0.315 171.657 valid loss: 166.768 valid auc 0.894 valid r2 0.490\n",
      "\tTrain loss: 0.315 154.887 valid loss: 170.290 valid auc 0.895 valid r2 0.479\n",
      "\tTrain loss: 0.307 150.405 valid loss: 160.113 valid auc 0.899 valid r2 0.510\n",
      "\tTrain loss: 0.305 138.413 valid loss: 149.179 valid auc 0.902 valid r2 0.544\n",
      "\tTrain loss: 0.301 131.003 valid loss: 141.377 valid auc 0.903 valid r2 0.568\n",
      "\tTrain loss: 0.300 125.492 valid loss: 137.444 valid auc 0.905 valid r2 0.580\n",
      "\tTrain loss: 0.298 123.243 valid loss: 132.596 valid auc 0.908 valid r2 0.595\n",
      "\tTrain loss: 0.297 118.913 valid loss: 130.229 valid auc 0.910 valid r2 0.602\n",
      "\tTrain loss: 0.294 115.787 valid loss: 126.330 valid auc 0.911 valid r2 0.614\n",
      "\tTrain loss: 0.292 112.236 valid loss: 124.773 valid auc 0.912 valid r2 0.618\n"
     ]
    }
   ],
   "source": [
    "model = EventModel2().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model2\",epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.406 112.307 valid loss: 119.428 valid auc 0.913 valid r2 0.635\n",
      "\tTrain loss: 0.333 107.575 valid loss: 115.385 valid auc 0.914 valid r2 0.647\n",
      "\tTrain loss: 0.322 100.261 valid loss: 109.791 valid auc 0.914 valid r2 0.664\n",
      "\tTrain loss: 0.303 98.183 valid loss: 108.314 valid auc 0.907 valid r2 0.669\n",
      "\tTrain loss: 0.302 95.526 valid loss: 107.107 valid auc 0.908 valid r2 0.673\n",
      "\tTrain loss: 0.293 94.367 valid loss: 105.183 valid auc 0.910 valid r2 0.679\n",
      "\tTrain loss: 0.285 91.069 valid loss: 103.386 valid auc 0.912 valid r2 0.684\n",
      "\tTrain loss: 0.284 89.615 valid loss: 101.989 valid auc 0.915 valid r2 0.688\n",
      "\tTrain loss: 0.281 88.145 valid loss: 101.753 valid auc 0.916 valid r2 0.689\n",
      "\tTrain loss: 0.278 87.158 valid loss: 102.721 valid auc 0.916 valid r2 0.686\n",
      "\tTrain loss: 0.275 86.722 valid loss: 100.385 valid auc 0.918 valid r2 0.693\n",
      "\tTrain loss: 0.274 85.826 valid loss: 102.717 valid auc 0.918 valid r2 0.686\n",
      "\tTrain loss: 0.273 84.735 valid loss: 99.850 valid auc 0.920 valid r2 0.695\n",
      "\tTrain loss: 0.271 84.530 valid loss: 105.804 valid auc 0.920 valid r2 0.677\n",
      "\tTrain loss: 0.276 86.886 valid loss: 104.557 valid auc 0.918 valid r2 0.680\n",
      "\tTrain loss: 0.275 86.151 valid loss: 102.855 valid auc 0.919 valid r2 0.686\n",
      "\tTrain loss: 0.279 84.809 valid loss: 102.989 valid auc 0.919 valid r2 0.685\n",
      "\tTrain loss: 0.280 82.727 valid loss: 101.804 valid auc 0.922 valid r2 0.689\n",
      "\tTrain loss: 0.273 82.547 valid loss: 99.930 valid auc 0.924 valid r2 0.695\n",
      "\tTrain loss: 0.269 81.979 valid loss: 102.836 valid auc 0.924 valid r2 0.686\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model2\", epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.559 6478.740 valid loss: 6720.069 valid auc 0.903 valid r2 -19.594\n",
      "\tTrain loss: 0.400 3865.623 valid loss: 876.103 valid auc 0.884 valid r2 -1.684\n",
      "\tTrain loss: 0.403 541.460 valid loss: 423.335 valid auc 0.912 valid r2 -0.295\n",
      "\tTrain loss: 0.368 680.451 valid loss: 316.751 valid auc 0.916 valid r2 0.031\n",
      "\tTrain loss: 0.317 159.442 valid loss: 311.143 valid auc 0.922 valid r2 0.048\n",
      "\tTrain loss: 0.302 215.688 valid loss: 238.342 valid auc 0.917 valid r2 0.270\n",
      "\tTrain loss: 0.287 108.489 valid loss: 109.523 valid auc 0.917 valid r2 0.665\n",
      "\tTrain loss: 0.287 103.985 valid loss: 124.528 valid auc 0.919 valid r2 0.619\n",
      "\tTrain loss: 0.280 80.234 valid loss: 112.783 valid auc 0.924 valid r2 0.655\n",
      "\tTrain loss: 0.280 80.430 valid loss: 105.465 valid auc 0.923 valid r2 0.678\n",
      "\tTrain loss: 0.275 71.782 valid loss: 106.589 valid auc 0.923 valid r2 0.674\n",
      "\tTrain loss: 0.268 71.114 valid loss: 104.627 valid auc 0.925 valid r2 0.680\n",
      "\tTrain loss: 0.264 68.091 valid loss: 100.808 valid auc 0.926 valid r2 0.692\n",
      "\tTrain loss: 0.264 68.164 valid loss: 107.879 valid auc 0.925 valid r2 0.670\n",
      "\tTrain loss: 0.265 65.955 valid loss: 104.871 valid auc 0.923 valid r2 0.679\n"
     ]
    }
   ],
   "source": [
    "model = EventModel3().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model3\", epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.298 80.243 valid loss: 103.825 valid auc 0.922 valid r2 0.683\n",
      "\tTrain loss: 0.284 71.912 valid loss: 101.770 valid auc 0.926 valid r2 0.689\n",
      "\tTrain loss: 0.267 68.668 valid loss: 102.958 valid auc 0.924 valid r2 0.685\n",
      "\tTrain loss: 0.268 65.787 valid loss: 99.084 valid auc 0.926 valid r2 0.697\n",
      "\tTrain loss: 0.265 62.985 valid loss: 97.094 valid auc 0.927 valid r2 0.703\n",
      "\tTrain loss: 0.263 62.857 valid loss: 97.487 valid auc 0.928 valid r2 0.702\n",
      "\tTrain loss: 0.261 60.795 valid loss: 102.769 valid auc 0.926 valid r2 0.686\n",
      "\tTrain loss: 0.261 60.218 valid loss: 100.094 valid auc 0.926 valid r2 0.694\n",
      "\tTrain loss: 0.261 59.393 valid loss: 100.960 valid auc 0.925 valid r2 0.691\n",
      "\tTrain loss: 0.261 59.544 valid loss: 101.426 valid auc 0.925 valid r2 0.690\n",
      "\tTrain loss: 0.260 59.148 valid loss: 103.277 valid auc 0.928 valid r2 0.684\n",
      "\tTrain loss: 0.259 59.859 valid loss: 106.057 valid auc 0.926 valid r2 0.676\n",
      "\tTrain loss: 0.263 58.990 valid loss: 106.090 valid auc 0.927 valid r2 0.676\n",
      "\tTrain loss: 0.267 59.694 valid loss: 105.139 valid auc 0.928 valid r2 0.679\n",
      "\tTrain loss: 0.262 60.138 valid loss: 101.745 valid auc 0.924 valid r2 0.689\n",
      "\tTrain loss: 0.261 59.068 valid loss: 101.632 valid auc 0.929 valid r2 0.689\n",
      "\tTrain loss: 0.259 59.115 valid loss: 105.067 valid auc 0.924 valid r2 0.679\n",
      "\tTrain loss: 0.264 59.742 valid loss: 102.172 valid auc 0.927 valid r2 0.688\n",
      "\tTrain loss: 0.259 58.755 valid loss: 99.740 valid auc 0.928 valid r2 0.695\n",
      "\tTrain loss: 0.262 62.490 valid loss: 104.673 valid auc 0.922 valid r2 0.680\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model3\", epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel4(nn.Module):\n",
    "    def __init__(self, hidden_size=100, num2=50):\n",
    "        super(EventModel4, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(5, hidden_size, batch_first=True)\n",
    "        self.num1 = hidden_size + 7 + 1\n",
    "        self.num2 = num2\n",
    "        self.linear1 = nn.Linear(self.num1, self.num2)\n",
    "        self.linear2 = nn.Linear(self.num2, self.num2)\n",
    "        self.out1 = nn.Linear(self.num2, 1)\n",
    "        self.out2 = nn.Linear(self.num2, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.num2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.num2)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.644 6727.855 valid loss: 6425.686 valid auc 0.914 valid r2 -18.691\n",
      "\tTrain loss: 0.362 5981.286 valid loss: 5965.913 valid auc 0.918 valid r2 -17.282\n",
      "\tTrain loss: 0.286 4673.132 valid loss: 4095.199 valid auc 0.907 valid r2 -11.551\n",
      "\tTrain loss: 0.408 2928.703 valid loss: 2970.744 valid auc 0.890 valid r2 -8.104\n",
      "\tTrain loss: 0.426 1138.616 valid loss: 473.311 valid auc 0.870 valid r2 -0.449\n",
      "\tTrain loss: 0.286 168.259 valid loss: 184.248 valid auc 0.918 valid r2 0.436\n",
      "\tTrain loss: 0.279 198.884 valid loss: 292.111 valid auc 0.920 valid r2 0.106\n",
      "\tTrain loss: 0.279 221.210 valid loss: 104.622 valid auc 0.925 valid r2 0.680\n",
      "\tTrain loss: 0.269 91.116 valid loss: 115.318 valid auc 0.924 valid r2 0.648\n",
      "\tTrain loss: 0.269 80.125 valid loss: 142.325 valid auc 0.922 valid r2 0.565\n",
      "\tTrain loss: 0.268 85.085 valid loss: 111.255 valid auc 0.924 valid r2 0.660\n",
      "\tTrain loss: 0.266 70.593 valid loss: 99.771 valid auc 0.922 valid r2 0.695\n",
      "\tTrain loss: 0.268 67.891 valid loss: 97.212 valid auc 0.924 valid r2 0.703\n",
      "/data2/yinterian/multi-task-romain/models/model4_r2_70_auc_92.pth\n",
      "\tTrain loss: 0.267 69.556 valid loss: 102.777 valid auc 0.926 valid r2 0.686\n",
      "\tTrain loss: 0.265 65.557 valid loss: 112.017 valid auc 0.921 valid r2 0.658\n"
     ]
    }
   ],
   "source": [
    "model = EventModel4().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model4\", epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.272 71.874 valid loss: 107.673 valid auc 0.922 valid r2 0.671\n",
      "\tTrain loss: 0.272 69.203 valid loss: 99.756 valid auc 0.922 valid r2 0.695\n",
      "\tTrain loss: 0.268 65.662 valid loss: 97.234 valid auc 0.926 valid r2 0.703\n",
      "/data2/yinterian/multi-task-romain/models/model4_r2_70_auc_93.pth\n",
      "\tTrain loss: 0.264 63.336 valid loss: 97.215 valid auc 0.924 valid r2 0.703\n",
      "\tTrain loss: 0.267 63.886 valid loss: 101.242 valid auc 0.926 valid r2 0.691\n",
      "\tTrain loss: 0.262 61.971 valid loss: 99.132 valid auc 0.924 valid r2 0.697\n",
      "\tTrain loss: 0.265 60.070 valid loss: 98.696 valid auc 0.926 valid r2 0.698\n",
      "\tTrain loss: 0.264 60.566 valid loss: 104.278 valid auc 0.924 valid r2 0.681\n",
      "\tTrain loss: 0.263 59.844 valid loss: 99.391 valid auc 0.928 valid r2 0.696\n",
      "\tTrain loss: 0.263 59.616 valid loss: 102.974 valid auc 0.925 valid r2 0.685\n",
      "\tTrain loss: 0.262 58.269 valid loss: 106.032 valid auc 0.926 valid r2 0.676\n",
      "\tTrain loss: 0.261 57.311 valid loss: 101.623 valid auc 0.927 valid r2 0.689\n",
      "\tTrain loss: 0.260 56.317 valid loss: 101.065 valid auc 0.926 valid r2 0.691\n",
      "\tTrain loss: 0.261 55.652 valid loss: 112.644 valid auc 0.925 valid r2 0.656\n",
      "\tTrain loss: 0.262 55.095 valid loss: 103.966 valid auc 0.928 valid r2 0.682\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, filename=\"model4\", epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/\"obs_df_valid.pickle\", 'rb') as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"models/model4_r2_70_auc_93.pth\"\n",
    "model = EventModel4().cuda()\n",
    "load_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_obs_per_patient(valid, k=2):\n",
    "    \"\"\" Picks sample from valid up to k per patient.\n",
    "    \"\"\"\n",
    "    valid_sample = valid.groupby(\"subject_id\", group_keys=False).apply(lambda x: x.sample(min(len(x), k)))\n",
    "    return valid_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((311, 14), (7332, 14))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sample = pick_obs_per_patient(valid, k=2)\n",
    "valid_sample.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_small_ds = MultiTask(valid_sample, norm_dict)\n",
    "val_small_dl = DataLoader(val_small_ds, batch_size=311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.35871505737305, 0.9121883321229727, 0.7806261142805457)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, val_small_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_batch(model, dl):\n",
    "    for x_series, x_cont, x_cat, y1, y2 in dl:\n",
    "        x_series = x_series.float().cuda()\n",
    "        x_cont = x_cont.float().cuda()\n",
    "        x_cat = x_cat.long().cuda()\n",
    "        y1 = y1.float().cuda()\n",
    "        y2 = y2.float().cuda()\n",
    "        out1, out2 = model(x_series, x_cont, x_cat)\n",
    "    return out1.detach().cpu().numpy(), out2.detach().cpu().numpy(), y1.detach().cpu().numpy(), y2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, out2, y1, y2 = predict_one_batch(model, val_small_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out2, y2, 'bo')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21864952, 0.2057877813504823)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.mean(), (out1 > 0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
