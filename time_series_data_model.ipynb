{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/data2/yinterian/multi-task-romain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/\"obs_df_train.pickle\", 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/\"obs_df_valid.pickle\", 'rb') as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sapsi_first</th>\n",
       "      <th>sofa_first</th>\n",
       "      <th>care_unit</th>\n",
       "      <th>amine</th>\n",
       "      <th>sedation</th>\n",
       "      <th>ventilation</th>\n",
       "      <th>period</th>\n",
       "      <th>series</th>\n",
       "      <th>y_event</th>\n",
       "      <th>y_mean_abpm</th>\n",
       "      <th>is_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[[85.0, 89.1, 106.8, 31.5, 52.2, 1.0], [84.9, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>62.465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[[85.9, 88.3, 123.2, 38.6, 63.2, 1.0], [85.5, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>56.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[[85.6, 93.6, 108.4, 34.7, 55.9, 1.0], [86.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>60.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[[86.9, 0.0, 95.3, 30.0, 48.5, 1.0], [87.4, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>55.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[[87.3, 90.6, 105.9, 36.1, 55.9, 1.0], [86.8, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>57.965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  gender age sapsi_first sofa_first  care_unit amine sedation  \\\n",
       "0      10013       1  87          15          8          0     1        0   \n",
       "1      10013       1  87          15          8          0     1        0   \n",
       "2      10013       1  87          15          8          0     1        0   \n",
       "3      10013       1  87          15          8          0     1        0   \n",
       "4      10013       1  87          15          8          0     1        0   \n",
       "\n",
       "  ventilation period                                             series  \\\n",
       "0           0     10  [[85.0, 89.1, 106.8, 31.5, 52.2, 1.0], [84.9, ...   \n",
       "1           0     11  [[85.9, 88.3, 123.2, 38.6, 63.2, 1.0], [85.5, ...   \n",
       "2           0     12  [[85.6, 93.6, 108.4, 34.7, 55.9, 1.0], [86.0, ...   \n",
       "3           0     15  [[86.9, 0.0, 95.3, 30.0, 48.5, 1.0], [87.4, 0....   \n",
       "4           0     16  [[87.3, 90.6, 105.9, 36.1, 55.9, 1.0], [86.8, ...   \n",
       "\n",
       "  y_event y_mean_abpm  is_val  \n",
       "0       1      62.465       0  \n",
       "1       1      56.505       0  \n",
       "2       1       60.52       0  \n",
       "3       1       55.23       0  \n",
       "4       1      57.965       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sapsi_first</th>\n",
       "      <th>sofa_first</th>\n",
       "      <th>care_unit</th>\n",
       "      <th>amine</th>\n",
       "      <th>sedation</th>\n",
       "      <th>ventilation</th>\n",
       "      <th>period</th>\n",
       "      <th>series</th>\n",
       "      <th>y_event</th>\n",
       "      <th>y_mean_abpm</th>\n",
       "      <th>is_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[101.1, 100.0, 149.3, 94.5, 115.7, 0.0], [101...</td>\n",
       "      <td>0</td>\n",
       "      <td>107.575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>[[89.0, 100.0, 133.6, 69.2, 88.2, 0.0], [89.1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>90.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>[[89.8, 97.9, 141.9, 71.2, 89.9, 0.0], [89.8, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>96.515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>[[89.4, 99.0, 159.3, 77.4, 98.1, 0.0], [89.1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>97.355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>10209</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>[[87.0, 99.0, 166.9, 78.4, 101.6, 0.0], [90.6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>102.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  gender age sapsi_first sofa_first  care_unit amine sedation  \\\n",
       "221      10209       0  35          16          7          1     1        1   \n",
       "222      10209       0  35          16          7          1     1        1   \n",
       "223      10209       0  35          16          7          1     1        1   \n",
       "224      10209       0  35          16          7          1     1        1   \n",
       "225      10209       0  35          16          7          1     1        1   \n",
       "\n",
       "    ventilation period                                             series  \\\n",
       "221           1     10  [[101.1, 100.0, 149.3, 94.5, 115.7, 0.0], [101...   \n",
       "222           1    102  [[89.0, 100.0, 133.6, 69.2, 88.2, 0.0], [89.1,...   \n",
       "223           1    103  [[89.8, 97.9, 141.9, 71.2, 89.9, 0.0], [89.8, ...   \n",
       "224           1    104  [[89.4, 99.0, 159.3, 77.4, 98.1, 0.0], [89.1, ...   \n",
       "225           1    106  [[87.0, 99.0, 166.9, 78.4, 101.6, 0.0], [90.6,...   \n",
       "\n",
       "    y_event y_mean_abpm  is_val  \n",
       "221       0     107.575       1  \n",
       "222       0       90.04       1  \n",
       "223       0      96.515       1  \n",
       "224       0      97.355       1  \n",
       "225       0      102.24       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32256, 14), (7332, 14))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_series(train):\n",
    "    ss = np.concatenate(train.series.values)\n",
    "    ss = ss.reshape(-1,6)\n",
    "    return ss.mean(axis=0), ss.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_static(train):\n",
    "    res = {}\n",
    "    for name in [\"age\", \"sapsi_first\", \"sofa_first\"]:\n",
    "        values = train[name].values\n",
    "        res[name] = (values.mean(), values.std())\n",
    "    res[\"series\"] = get_mean_std_series(train)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': (67, 16.152217089222916),\n",
       " 'sapsi_first': (16, 4.968204119744002),\n",
       " 'sofa_first': (8, 4.153183597602336),\n",
       " 'series': (array([ 85.78689748,  90.61373362, 118.25838821,  57.44024058,\n",
       "          81.28476211,   0.17137897]),\n",
       "  array([16.91317423, 24.11194065, 31.60648773, 17.01183444, 20.30982141,\n",
       "          0.37683978]))}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict = get_mean_std_static(train)\n",
    "norm_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTask(Dataset):\n",
    "    def __init__(self, df, norm_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: dataframe with data\n",
    "            norm_dict: mean and std of all variables to normalize\n",
    "            \n",
    "        \"\"\"\n",
    "        self.norm_dict = norm_dict\n",
    "        self.df = df\n",
    "        self.names = [\"age\", \"sapsi_first\", \"sofa_first\"] ## needs normalization\n",
    "        self.names_binary = [\"gender\", \"amine\", \"sedation\", \"ventilation\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index,:]\n",
    "        x_series = (row.series - self.norm_dict[\"series\"][0])/self.norm_dict[\"series\"][1]\n",
    "        x_cont = [(row[name]-self.norm_dict[name][0])/self.norm_dict[name][1] for name in self.names]\n",
    "        x_binary = [row[name] for name in self.names_binary]\n",
    "        x_cat = row[\"care_unit\"]\n",
    "        x_cont = np.array(x_cont + x_binary)\n",
    "        return x_series, x_cont, x_cat, row[\"y_event\"], row[\"y_mean_abpm\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MultiTask(train, norm_dict)\n",
    "valid_ds = MultiTask(valid, norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_series, x_cont, x_cat, y1, y2 = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(6, 11, bidirectional=True, batch_first=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 11])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts, ht = gru(x_series.float().cuda())\n",
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 11]), torch.Size([5, 11]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[0].shape, ht[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 11])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "embedding = nn.Embedding(3, 1).cuda()\n",
    "gru = nn.GRU(6, hidden_size, bidirectional=True, batch_first=True).cuda()\n",
    "num = hidden_size + 10 + 1\n",
    "linear1 = nn.Linear(7, 10).cuda()\n",
    "out1 = nn.Linear(num, 1).cuda()\n",
    "out2 = nn.Linear(num, 1).cuda()\n",
    "bn1 = nn.BatchNorm1d(10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_series, x_cont, x_cat, y1, y2 = next(iter(train_dl))\n",
    "x_series = x_series.float().cuda()\n",
    "x_cont = x_cont.float().cuda()\n",
    "x_cat = x_cat.long().cuda()\n",
    "y1 = y1.float().cuda()\n",
    "y2 = y2.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ht = gru(x_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(EventModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(6, hidden_size, batch_first=True)\n",
    "        self.num = hidden_size + 10 + 1\n",
    "        self.linear1 = nn.Linear(7, 10)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x_cont = self.bn1(F.relu(self.linear1(x_cont))) \n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel2(nn.Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        super(EventModel2, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(6, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.num = 2*hidden_size + 7 + 1\n",
    "        self.linear1 = nn.Linear(7, 7)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x_cont = self.bn1(F.relu(self.linear1(x_cont))) + x_cont\n",
    "        x = torch.cat((ht[0], ht[1], x_cat, x_cont), 1)\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventModel3(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(EventModel3, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, 1)\n",
    "        self.gru = nn.GRU(6, hidden_size, batch_first=True)\n",
    "        self.num = hidden_size + 7 + 1\n",
    "        self.linear1 = nn.Linear(7, 7)\n",
    "        self.out1 = nn.Linear(self.num, 1)\n",
    "        self.out2 = nn.Linear(self.num, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    def forward(self, x_series, x_cont, x_cat):\n",
    "        _, ht = self.gru(x_series)\n",
    "        x_cat = self.embedding(x_cat)\n",
    "        x_cont = self.bn1(F.relu(self.linear1(x_cont))) + x_cont\n",
    "        x = torch.cat((ht[-1], x_cat, x_cont), 1)\n",
    "        return self.out1(x), self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    y_hat1 = []\n",
    "    ys1 = []\n",
    "    y_hat2 = []\n",
    "    ys2 = []\n",
    "    for x_series, x_cont, x_cat, y1, y2 in valid_dl:\n",
    "        batch = y1.shape[0]\n",
    "        x_series = x_series.float().cuda()\n",
    "        x_cont = x_cont.float().cuda()\n",
    "        x_cat = x_cat.long().cuda()\n",
    "        y1 = y1.float().cuda()\n",
    "        y2 = y2.float().cuda()\n",
    "        out1, out2 = model(x_series, x_cont, x_cat)\n",
    "        log_loss = F.binary_cross_entropy_with_logits(out1, y1.unsqueeze(-1))\n",
    "        mse_loss = F.mse_loss(out2, y2.unsqueeze(-1))\n",
    "        loss = log_loss + mse_loss\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        y_hat1.append(out1.view(-1).detach().cpu().numpy())\n",
    "        ys1.append(y1.view(-1).cpu().numpy())\n",
    "        y_hat2.append(out2.view(-1).detach().cpu().numpy())\n",
    "        ys2.append(y2.view(-1).cpu().numpy())\n",
    "    \n",
    "    y_hat1 = np.concatenate(y_hat1)\n",
    "    y_hat2 = np.concatenate(y_hat2)\n",
    "    ys1 = np.concatenate(ys1)\n",
    "    ys2 = np.concatenate(ys2)\n",
    "    r2 = metrics.r2_score(ys2, y_hat2)\n",
    "    auc = metrics.roc_auc_score(ys1, y_hat1)\n",
    "    return sum_loss/total, auc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, train_dl, optimizer, lr=1e-3, epochs = 30):\n",
    "    for i in range(epochs):\n",
    "        sum_loss1 = 0\n",
    "        sum_loss2 = 0\n",
    "        total = 0\n",
    "        for x_series, x_cont, x_cat, y1, y2 in train_dl:\n",
    "            model.train()\n",
    "            x_series = x_series.float().cuda()\n",
    "            x_cont = x_cont.float().cuda()\n",
    "            x_cat = x_cat.long().cuda()\n",
    "            y1 = y1.float().cuda()\n",
    "            y2 = y2.float().cuda()\n",
    "            out1, out2 = model(x_series, x_cont, x_cat)\n",
    "            log_loss = F.binary_cross_entropy_with_logits(out1, y1.unsqueeze(-1))\n",
    "            mse_loss = F.mse_loss(out2, y2.unsqueeze(-1))\n",
    "            loss = log_loss + mse_loss\n",
    "            sum_loss1 += len(y1) * log_loss.item()\n",
    "            sum_loss2 += len(y1) * mse_loss.item()\n",
    "            total += len(y1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #val_loss, val_r2 = val_metrics2(model, val_dl2)  # val_dl\n",
    "            #  Valid loss: {:.3f} {:.3f} \\t Valid R2:  {:.3f}\n",
    "        if i % 1 == 0:\n",
    "            val_loss, val_auc, val_r2 = val_metrics(model, valid_dl)\n",
    "            print(\"\\tTrain loss: {:.3f} {:.3f} valid loss: {:.3f} valid auc {:.3f} valid r2 {:.3f}\".format(\n",
    "                sum_loss1/total, sum_loss2/total, val_loss, val_auc, val_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EventModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.457 5476.242 valid loss: 3371.622 valid auc 0.984 valid r2 -9.333\n",
      "\tTrain loss: 0.163 2287.411 valid loss: 866.005 valid auc 0.990 valid r2 -1.654\n",
      "\tTrain loss: 0.066 455.009 valid loss: 232.331 valid auc 0.999 valid r2 0.288\n",
      "\tTrain loss: 0.023 269.016 valid loss: 381.748 valid auc 0.997 valid r2 -0.170\n",
      "\tTrain loss: 0.052 249.567 valid loss: 190.040 valid auc 0.988 valid r2 0.418\n",
      "\tTrain loss: 0.120 146.674 valid loss: 156.164 valid auc 0.976 valid r2 0.522\n",
      "\tTrain loss: 0.129 144.540 valid loss: 152.921 valid auc 0.985 valid r2 0.532\n",
      "\tTrain loss: 0.070 132.529 valid loss: 138.863 valid auc 0.995 valid r2 0.575\n",
      "\tTrain loss: 0.039 123.282 valid loss: 135.208 valid auc 0.996 valid r2 0.586\n",
      "\tTrain loss: 0.033 119.760 valid loss: 129.378 valid auc 0.995 valid r2 0.604\n",
      "\tTrain loss: 0.029 115.332 valid loss: 127.812 valid auc 0.995 valid r2 0.608\n",
      "\tTrain loss: 0.025 113.677 valid loss: 124.155 valid auc 0.996 valid r2 0.620\n",
      "\tTrain loss: 0.021 110.993 valid loss: 122.927 valid auc 0.997 valid r2 0.623\n",
      "\tTrain loss: 0.018 108.947 valid loss: 119.599 valid auc 0.998 valid r2 0.633\n",
      "\tTrain loss: 0.015 108.559 valid loss: 119.957 valid auc 0.998 valid r2 0.632\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, train_dl, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.018 106.256 valid loss: 114.914 valid auc 0.999 valid r2 0.648\n",
      "\tTrain loss: 0.009 103.002 valid loss: 110.028 valid auc 0.999 valid r2 0.663\n",
      "\tTrain loss: 0.005 97.049 valid loss: 106.884 valid auc 1.000 valid r2 0.672\n",
      "\tTrain loss: 0.002 93.201 valid loss: 103.082 valid auc 1.000 valid r2 0.684\n",
      "\tTrain loss: 0.001 89.498 valid loss: 104.673 valid auc 1.000 valid r2 0.679\n",
      "\tTrain loss: 0.001 91.438 valid loss: 100.413 valid auc 1.000 valid r2 0.692\n",
      "\tTrain loss: 0.000 86.177 valid loss: 96.543 valid auc 1.000 valid r2 0.704\n",
      "\tTrain loss: 0.000 85.200 valid loss: 96.200 valid auc 1.000 valid r2 0.705\n",
      "\tTrain loss: 0.000 82.420 valid loss: 95.452 valid auc 1.000 valid r2 0.707\n",
      "\tTrain loss: 0.000 81.668 valid loss: 96.489 valid auc 1.000 valid r2 0.704\n",
      "\tTrain loss: 0.000 81.975 valid loss: 95.094 valid auc 1.000 valid r2 0.709\n",
      "\tTrain loss: 0.000 81.277 valid loss: 94.531 valid auc 1.000 valid r2 0.710\n",
      "\tTrain loss: 0.000 80.508 valid loss: 93.134 valid auc 1.000 valid r2 0.715\n",
      "\tTrain loss: 0.000 79.749 valid loss: 94.898 valid auc 1.000 valid r2 0.709\n",
      "\tTrain loss: 0.000 78.663 valid loss: 92.904 valid auc 1.000 valid r2 0.715\n",
      "\tTrain loss: 0.000 78.949 valid loss: 92.776 valid auc 1.000 valid r2 0.716\n",
      "\tTrain loss: 0.000 78.361 valid loss: 95.694 valid auc 1.000 valid r2 0.707\n",
      "\tTrain loss: 0.000 77.959 valid loss: 96.631 valid auc 1.000 valid r2 0.704\n",
      "\tTrain loss: 0.000 77.552 valid loss: 93.608 valid auc 1.000 valid r2 0.713\n",
      "\tTrain loss: 0.000 76.386 valid loss: 92.791 valid auc 1.000 valid r2 0.716\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"{0}/models/model_acc_1_r2_{1:.0f}.pth\".format(PATH, 100*0.71) \n",
    "save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.510 5661.317 valid loss: 3645.168 valid auc 0.979 valid r2 -10.171\n",
      "\tTrain loss: 0.288 2402.384 valid loss: 1024.066 valid auc 0.996 valid r2 -2.138\n",
      "\tTrain loss: 0.071 445.740 valid loss: 204.697 valid auc 0.999 valid r2 0.373\n",
      "\tTrain loss: 0.040 295.383 valid loss: 353.198 valid auc 0.995 valid r2 -0.082\n",
      "\tTrain loss: 0.123 286.915 valid loss: 185.472 valid auc 0.978 valid r2 0.432\n",
      "\tTrain loss: 0.198 150.172 valid loss: 162.997 valid auc 0.976 valid r2 0.501\n",
      "\tTrain loss: 0.138 147.899 valid loss: 158.680 valid auc 0.991 valid r2 0.514\n",
      "\tTrain loss: 0.064 132.395 valid loss: 136.314 valid auc 0.998 valid r2 0.582\n",
      "\tTrain loss: 0.030 118.771 valid loss: 128.493 valid auc 0.999 valid r2 0.606\n",
      "\tTrain loss: 0.025 112.281 valid loss: 121.999 valid auc 0.999 valid r2 0.626\n"
     ]
    }
   ],
   "source": [
    "# new try\n",
    "model = ReviewModel().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=1e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.030 107.457 valid loss: 114.954 valid auc 0.999 valid r2 0.648\n",
      "\tTrain loss: 0.016 99.500 valid loss: 108.701 valid auc 0.999 valid r2 0.667\n",
      "\tTrain loss: 0.012 93.712 valid loss: 104.976 valid auc 0.999 valid r2 0.678\n",
      "\tTrain loss: 0.009 91.632 valid loss: 103.072 valid auc 1.000 valid r2 0.684\n",
      "\tTrain loss: 0.005 86.938 valid loss: 98.072 valid auc 1.000 valid r2 0.699\n",
      "\tTrain loss: 0.003 84.544 valid loss: 96.656 valid auc 1.000 valid r2 0.704\n",
      "\tTrain loss: 0.002 84.164 valid loss: 95.917 valid auc 1.000 valid r2 0.706\n",
      "\tTrain loss: 0.002 81.947 valid loss: 94.791 valid auc 1.000 valid r2 0.709\n",
      "\tTrain loss: 0.002 80.682 valid loss: 93.909 valid auc 1.000 valid r2 0.712\n",
      "\tTrain loss: 0.002 79.567 valid loss: 93.170 valid auc 1.000 valid r2 0.714\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"{0}/models/model_acc_1_r2_{1:.0f}.pth\".format(PATH, 100*0.71) \n",
    "save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.515 5614.094 valid loss: 3347.934 valid auc 0.963 valid r2 -9.260\n",
      "\tTrain loss: 0.296 2136.751 valid loss: 786.024 valid auc 0.994 valid r2 -1.409\n",
      "\tTrain loss: 0.081 370.051 valid loss: 245.979 valid auc 0.999 valid r2 0.246\n",
      "\tTrain loss: 0.039 311.871 valid loss: 268.143 valid auc 0.997 valid r2 0.178\n",
      "\tTrain loss: 0.073 196.453 valid loss: 160.368 valid auc 0.987 valid r2 0.509\n",
      "\tTrain loss: 0.115 136.225 valid loss: 150.191 valid auc 0.982 valid r2 0.540\n",
      "\tTrain loss: 0.105 127.142 valid loss: 134.692 valid auc 0.992 valid r2 0.587\n",
      "\tTrain loss: 0.061 117.468 valid loss: 127.828 valid auc 0.994 valid r2 0.608\n",
      "\tTrain loss: 0.041 112.376 valid loss: 123.768 valid auc 0.996 valid r2 0.621\n",
      "\tTrain loss: 0.030 107.708 valid loss: 122.921 valid auc 0.996 valid r2 0.623\n",
      "\tTrain loss: 0.023 105.248 valid loss: 120.223 valid auc 0.997 valid r2 0.632\n",
      "\tTrain loss: 0.019 102.736 valid loss: 114.898 valid auc 0.998 valid r2 0.648\n",
      "\tTrain loss: 0.016 99.834 valid loss: 112.167 valid auc 0.998 valid r2 0.656\n",
      "\tTrain loss: 0.014 98.367 valid loss: 109.683 valid auc 0.998 valid r2 0.664\n",
      "\tTrain loss: 0.015 107.010 valid loss: 134.649 valid auc 0.999 valid r2 0.587\n"
     ]
    }
   ],
   "source": [
    "# new try\n",
    "model = ReviewModel().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.017 115.906 valid loss: 115.094 valid auc 0.998 valid r2 0.647\n",
      "\tTrain loss: 0.011 99.338 valid loss: 110.153 valid auc 0.999 valid r2 0.662\n",
      "\tTrain loss: 0.008 93.230 valid loss: 105.050 valid auc 0.999 valid r2 0.678\n",
      "\tTrain loss: 0.007 89.889 valid loss: 102.571 valid auc 1.000 valid r2 0.686\n",
      "\tTrain loss: 0.003 87.512 valid loss: 101.051 valid auc 1.000 valid r2 0.690\n",
      "\tTrain loss: 0.002 86.400 valid loss: 99.636 valid auc 1.000 valid r2 0.695\n",
      "\tTrain loss: 0.001 84.975 valid loss: 99.361 valid auc 1.000 valid r2 0.695\n",
      "\tTrain loss: 0.001 82.448 valid loss: 97.378 valid auc 1.000 valid r2 0.702\n",
      "\tTrain loss: 0.001 81.799 valid loss: 97.014 valid auc 1.000 valid r2 0.703\n",
      "\tTrain loss: 0.001 81.172 valid loss: 96.950 valid auc 1.000 valid r2 0.703\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.003 80.319 valid loss: 97.518 valid auc 1.000 valid r2 0.701\n",
      "\tTrain loss: 0.002 79.188 valid loss: 95.136 valid auc 1.000 valid r2 0.708\n",
      "\tTrain loss: 0.002 78.780 valid loss: 97.277 valid auc 1.000 valid r2 0.702\n",
      "\tTrain loss: 0.002 78.105 valid loss: 95.397 valid auc 1.000 valid r2 0.708\n",
      "\tTrain loss: 0.002 77.212 valid loss: 95.913 valid auc 1.000 valid r2 0.706\n",
      "\tTrain loss: 0.001 77.310 valid loss: 94.746 valid auc 1.000 valid r2 0.710\n",
      "\tTrain loss: 0.001 76.886 valid loss: 96.049 valid auc 1.000 valid r2 0.706\n",
      "\tTrain loss: 0.001 75.821 valid loss: 95.151 valid auc 1.000 valid r2 0.708\n",
      "\tTrain loss: 0.002 75.586 valid loss: 96.667 valid auc 1.000 valid r2 0.704\n",
      "\tTrain loss: 0.002 76.552 valid loss: 105.541 valid auc 1.000 valid r2 0.677\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.512 5396.758 valid loss: 2867.637 valid auc 0.748 valid r2 -7.788\n",
      "\tTrain loss: 0.476 1736.363 valid loss: 561.296 valid auc 0.888 valid r2 -0.719\n",
      "\tTrain loss: 0.329 332.075 valid loss: 360.509 valid auc 0.972 valid r2 -0.104\n",
      "\tTrain loss: 0.247 376.701 valid loss: 405.927 valid auc 0.961 valid r2 -0.243\n",
      "\tTrain loss: 0.264 299.431 valid loss: 256.057 valid auc 0.910 valid r2 0.216\n",
      "\tTrain loss: 0.311 193.591 valid loss: 210.667 valid auc 0.900 valid r2 0.355\n",
      "\tTrain loss: 0.309 178.996 valid loss: 195.992 valid auc 0.954 valid r2 0.400\n",
      "\tTrain loss: 0.273 162.775 valid loss: 178.908 valid auc 0.978 valid r2 0.452\n",
      "\tTrain loss: 0.222 154.556 valid loss: 171.005 valid auc 0.986 valid r2 0.476\n",
      "\tTrain loss: 0.176 148.443 valid loss: 160.542 valid auc 0.990 valid r2 0.508\n"
     ]
    }
   ],
   "source": [
    "model = EventModel2().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.205 138.009 valid loss: 142.054 valid auc 0.992 valid r2 0.565\n",
      "\tTrain loss: 0.123 119.375 valid loss: 121.359 valid auc 0.994 valid r2 0.628\n",
      "\tTrain loss: 0.092 104.652 valid loss: 112.241 valid auc 0.994 valid r2 0.656\n",
      "\tTrain loss: 0.071 96.723 valid loss: 106.069 valid auc 0.995 valid r2 0.675\n",
      "\tTrain loss: 0.061 91.812 valid loss: 102.572 valid auc 0.996 valid r2 0.686\n",
      "\tTrain loss: 0.059 88.423 valid loss: 100.487 valid auc 0.997 valid r2 0.692\n",
      "\tTrain loss: 0.054 86.139 valid loss: 99.896 valid auc 0.997 valid r2 0.694\n",
      "\tTrain loss: 0.046 84.702 valid loss: 98.534 valid auc 0.997 valid r2 0.698\n",
      "\tTrain loss: 0.039 83.165 valid loss: 96.876 valid auc 0.998 valid r2 0.703\n",
      "\tTrain loss: 0.034 83.170 valid loss: 95.775 valid auc 0.998 valid r2 0.707\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.041 95.387 valid loss: 101.649 valid auc 0.998 valid r2 0.689\n",
      "\tTrain loss: 0.027 85.841 valid loss: 97.907 valid auc 0.998 valid r2 0.700\n",
      "\tTrain loss: 0.018 82.423 valid loss: 98.105 valid auc 0.999 valid r2 0.699\n",
      "\tTrain loss: 0.013 80.887 valid loss: 94.609 valid auc 0.999 valid r2 0.710\n",
      "\tTrain loss: 0.011 79.400 valid loss: 94.408 valid auc 0.999 valid r2 0.711\n",
      "\tTrain loss: 0.009 78.400 valid loss: 95.185 valid auc 0.999 valid r2 0.708\n",
      "\tTrain loss: 0.009 77.394 valid loss: 93.863 valid auc 0.999 valid r2 0.712\n",
      "\tTrain loss: 0.009 76.556 valid loss: 92.947 valid auc 0.999 valid r2 0.715\n",
      "\tTrain loss: 0.009 76.214 valid loss: 93.462 valid auc 0.999 valid r2 0.714\n",
      "\tTrain loss: 0.008 75.490 valid loss: 92.902 valid auc 0.999 valid r2 0.715\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.011 83.232 valid loss: 101.910 valid auc 0.999 valid r2 0.688\n",
      "\tTrain loss: 0.009 80.226 valid loss: 95.778 valid auc 0.999 valid r2 0.706\n",
      "\tTrain loss: 0.008 77.625 valid loss: 94.975 valid auc 0.999 valid r2 0.709\n",
      "\tTrain loss: 0.006 75.138 valid loss: 93.962 valid auc 0.998 valid r2 0.712\n",
      "\tTrain loss: 0.005 74.046 valid loss: 94.162 valid auc 0.999 valid r2 0.711\n",
      "\tTrain loss: 0.005 72.985 valid loss: 93.117 valid auc 0.999 valid r2 0.715\n",
      "\tTrain loss: 0.005 74.338 valid loss: 100.073 valid auc 0.999 valid r2 0.693\n",
      "\tTrain loss: 0.005 74.674 valid loss: 95.869 valid auc 0.999 valid r2 0.706\n",
      "\tTrain loss: 0.005 74.494 valid loss: 96.297 valid auc 0.999 valid r2 0.705\n",
      "\tTrain loss: 0.004 73.423 valid loss: 95.504 valid auc 0.999 valid r2 0.707\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.448 5422.415 valid loss: 3257.136 valid auc 0.965 valid r2 -8.982\n",
      "\tTrain loss: 0.188 2126.582 valid loss: 727.760 valid auc 0.982 valid r2 -1.230\n",
      "\tTrain loss: 0.101 382.944 valid loss: 262.469 valid auc 0.999 valid r2 0.196\n",
      "\tTrain loss: 0.050 286.992 valid loss: 394.148 valid auc 0.996 valid r2 -0.208\n",
      "\tTrain loss: 0.093 283.393 valid loss: 216.445 valid auc 0.985 valid r2 0.337\n",
      "\tTrain loss: 0.175 159.576 valid loss: 159.808 valid auc 0.971 valid r2 0.511\n",
      "\tTrain loss: 0.194 147.195 valid loss: 161.487 valid auc 0.980 valid r2 0.506\n",
      "\tTrain loss: 0.126 140.781 valid loss: 146.122 valid auc 0.993 valid r2 0.552\n",
      "\tTrain loss: 0.062 128.764 valid loss: 138.021 valid auc 0.997 valid r2 0.577\n",
      "\tTrain loss: 0.042 124.727 valid loss: 132.152 valid auc 0.998 valid r2 0.595\n",
      "\tTrain loss: 0.032 117.261 valid loss: 126.010 valid auc 0.998 valid r2 0.614\n",
      "\tTrain loss: 0.025 112.174 valid loss: 120.545 valid auc 0.997 valid r2 0.631\n",
      "\tTrain loss: 0.024 108.676 valid loss: 116.961 valid auc 0.998 valid r2 0.642\n",
      "\tTrain loss: 0.026 104.531 valid loss: 115.579 valid auc 0.999 valid r2 0.646\n",
      "\tTrain loss: 0.022 101.369 valid loss: 112.849 valid auc 0.998 valid r2 0.654\n"
     ]
    }
   ],
   "source": [
    "model = EventModel3().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss: 0.025 101.943 valid loss: 111.617 valid auc 0.998 valid r2 0.658\n",
      "\tTrain loss: 0.018 97.338 valid loss: 107.893 valid auc 0.998 valid r2 0.669\n",
      "\tTrain loss: 0.015 93.232 valid loss: 104.515 valid auc 0.999 valid r2 0.680\n",
      "\tTrain loss: 0.009 89.917 valid loss: 100.391 valid auc 0.999 valid r2 0.692\n",
      "\tTrain loss: 0.007 87.176 valid loss: 100.372 valid auc 0.999 valid r2 0.692\n",
      "\tTrain loss: 0.005 85.816 valid loss: 98.958 valid auc 1.000 valid r2 0.697\n",
      "\tTrain loss: 0.005 84.202 valid loss: 97.510 valid auc 1.000 valid r2 0.701\n",
      "\tTrain loss: 0.003 82.915 valid loss: 97.885 valid auc 1.000 valid r2 0.700\n",
      "\tTrain loss: 0.002 82.477 valid loss: 98.357 valid auc 1.000 valid r2 0.699\n",
      "\tTrain loss: 0.002 82.003 valid loss: 98.049 valid auc 1.000 valid r2 0.699\n",
      "\tTrain loss: 0.002 80.348 valid loss: 95.627 valid auc 1.000 valid r2 0.707\n",
      "\tTrain loss: 0.002 80.548 valid loss: 94.659 valid auc 1.000 valid r2 0.710\n",
      "\tTrain loss: 0.002 79.668 valid loss: 94.605 valid auc 1.000 valid r2 0.710\n",
      "\tTrain loss: 0.002 78.452 valid loss: 94.403 valid auc 1.000 valid r2 0.711\n",
      "\tTrain loss: 0.002 78.050 valid loss: 96.591 valid auc 1.000 valid r2 0.704\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=3e-5)\n",
    "train_epochs(model, train_dl, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
